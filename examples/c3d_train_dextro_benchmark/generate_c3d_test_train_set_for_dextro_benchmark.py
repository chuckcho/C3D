#!/usr/bin/env python
'''
Generates train/validation lists for C3D training purpose in following steps
(1) read benchmark video list (pre-generated by running manage_benchmark_dataset
    script)
(2) for each video in video list, check if the length is in a good range
(3) download (if needed) video from s3
(4) generate c3d-compatible training/val video list (space-separated txt):
    each row: [video file], [start frame number], [category_id]
'''

import sys
sys.path.append("/home/chuck/projects")

import re
import json
import cv2
import os
import random
import boto
import time
from common.env import environ
from common.s3_interface import S3Interface
from boto.s3.key import Key
from urlparse import urlparse
from os.path import splitext, basename
from collections import Counter

#import logging
#from common.dextro_logger import LOGGER
#LOGGER.setLevel(logging.DEBUG)
#LOGGER.addHandler(logging.StreamHandler())

def get_all_video_annotations(json_file):
    ''' get video list / annotations from already saved json file '''
    with open(json_file, 'r') as json_fp:
        video_list = json.load(json_fp)
    return video_list

def get_num_frames(video_file):
    ''' get number of fraemes for a given video file '''
    cap = cv2.VideoCapture(video_file)
    if not cap.isOpened():
        print "[Warning] Could not open video file={}".format(video_file)
        return
    num_frames = int(cap.get(cv2.cv.CV_CAP_PROP_FRAME_COUNT))
    cap.release()
    return num_frames

def time2frame(time_in_sec, num_frames, length):
    ''' convert time in second to 0-based frame count '''
    if length == 0.0:
        print "[Error] Video length must be positive!"
        return None

    # frame number starts from 0
    frame = int(round(float(time_in_sec) * (num_frames - 1) / length))
    return frame

def download_video_from_s3(video_file, force_download_from_s3=False):
    ''' download video from s3. returns a bool for downloading success '''

    if os.path.isfile(video_file) and \
       os.stat(video_file).st_size and \
       not force_download_from_s3:
        print("[Info] Video file has already been downloaded from s3 and "
              "saved as {}. Skipping downloading...".format(video_file))
    else:
        print("[Info] Downloading video from s3 and saving as {} ..."
              "".format(video_file))

        filename, file_ext = splitext(basename(video_file))

        videos_s3_folder_path = environ('VIDEOS_S3_FOLDER_PATH')
        video_s3_filename = "{}/{}".format(
                videos_s3_folder_path,
                filename + file_ext
                )

        s3_interface = S3Interface(environ('VIDEOS_S3_BUCKET'))
        video_key = Key(s3_interface.bucket, video_s3_filename)
        try:
            video_key.get_contents_to_filename(video_file)
        except boto.exception.S3ResponseError as error:
            print "[Warning] Download failed w/ status={}".format(
                    error.status
                    )
            return False
        video_key.close()

    return True

def preprocess(
        video_list,
        local_video_dir,
        video_length_threshold=(-1.0, 999999.0),
        force_download_from_s3=False
        ):
    ''' scan for useable videos (specified length range) '''

    good_video_list = []
    all_content_type_ids = []
    content_id_to_type_mapping = {}

    corrupted_videos = [
            '1442548398.98SKO9GA1BGF',
            '1442548225.64SZ95JFDEQC'
            ]

    # scanning for useable videos
    for video_count, video in enumerate(video_list):

        # video info
        video_url = video['original_url']
        video_length = video['length']
        print "-" * 79
        print("[Info] Pre-processing video ({}/{}): id={}, original_url={}, "
              "length={}...".format(
                      video_count + 1,
                      len(video_list),
                      video['id'],
                      video_url,
                      video_length
                      )
                )

        # get all content_types present in this video
        content_types = video['content_types']

        # check if video is known problematic beforehand (e.g. corrupted)
        if any(bad_video in video_url for bad_video in corrupted_videos):
            print("[Info] This video={} is known problemtaic. Skipping..."
                  "".format(video_url)
                  )
            continue

        # filter out videos that are too short or too long
        if video_length < video_length_threshold[0]:
            print("[Info] Video length={} is shorter than the threshold={}. "
                  "Skipping...".format(
                          video_length,
                          video_length_threshold[0]
                          )
                  )
            continue
        if video_length >= video_length_threshold[1]:
            print("[Info] Video length={} is longer than or equal to the "
                  "threshold={}. Skipping...".format(
                          video_length,
                          video_length_threshold[1]
                          )
                  )
            continue

        # videos in periscope-demo unavailable?
        unuseable_url_regex_filter = r'(youtu\.be|periscope-demo|twimg\.com)'
        if re.search(unuseable_url_regex_filter, video_url):
            print("[Info] This video seems not available in url={}"
                  ". Skipping...".format(video_url)
                  )
            continue

        # download file
        filename, file_ext = splitext(basename(urlparse(video_url).path))
        video_file = os.path.join(local_video_dir, filename + file_ext)
        if not download_video_from_s3(video_file, force_download_from_s3):
            continue

        # get mappings from content_type to temporary "id"
        video_annotations = video['video_annotations']

        # check for no annotation
        if video_annotations == []:
            print "[Info] - Video has no annotation. Skipping..."
            continue

        # time (second) to frame number conversion
        num_frames = get_num_frames(video_file)
        if num_frames < 0:
            print "[Warning] - This video has not been extracted. Skipping..."
            continue

        good_video_list.append(video)

        # get content_types in advance
        content_type_map = {}
        for video_annotation in video_annotations:
            content_type_map[
                    video_annotation['id']
                    ] = video_annotation['content_type_id']

        for video_annotation_scene in video['video_annotation_scenes']:
            content_type_id = content_type_map[
                    video_annotation_scene['video_annotation_id']
                    ]
            #pylint: disable=W0141,W0110
            content_type = filter(
                    lambda x: x['id'] == content_type_id, content_types
                    )[0]['name']
            all_content_type_ids.append(content_type_id)
            content_id_to_type_mapping[content_type_id] = content_type

    return good_video_list, all_content_type_ids, content_id_to_type_mapping

def remove_uncommon_videos(
            video_list,
            num_videos_per_content_type,
            min_num_videos_per_content_type=3
            ):
    ''' remove videos with least frequent content_type's '''

    new_video_list = []
    new_all_content_type_ids = []
    new_content_id_to_type_mapping = {}

    for video in video_list:
        # check if video contains a content_type that's too few in the whole
        # video list

        # get all content_types present in this video
        content_types = video['content_types']

        # get all content_types present in this video
        video_annotations = video['video_annotations']

        # get content_types in advance
        content_type_map = {}
        for video_annotation in video_annotations:
            content_type_map[
                    video_annotation['id']
                    ] = video_annotation['content_type_id']

        keep_this_video = False
        content_type_ids_per_video = []
        content_type_pairs_per_video = []

        # go over video_annotation_scenes
        for video_annotation_scene in video['video_annotation_scenes']:
            content_type_id = content_type_map[
                    video_annotation_scene['video_annotation_id']
                    ]
            #pylint: disable=W0141,W0110
            content_type = filter(
                    lambda x: x['id'] == content_type_id, content_types
                    )[0]['name']
            content_type_ids_per_video.append(content_type_id)
            content_type_pairs_per_video.append((content_type, content_type_id))

            if num_videos_per_content_type[
                    content_type_id
                    ] >= min_num_videos_per_content_type:
                keep_this_video = True

        if keep_this_video:
            print "[Debug] *keep* video={}, ct={}".format(
                    video['original_url'],
                    content_type_pairs_per_video
                    )
            new_video_list.append(video)
            new_all_content_type_ids.extend(content_type_ids_per_video)
            for ct, ct_id in content_type_pairs_per_video:
                new_content_id_to_type_mapping[ct_id] = ct
        else:
            print "[Debug] *skip* video={}, #videos/ct={}".format(
                    video['original_url'],
                    num_videos_per_content_type[content_type_id]
                    )

    return (new_video_list,
            new_all_content_type_ids,
            new_content_id_to_type_mapping)

def main():
    ''' main routine for processing all videos '''

    # local directory that stores videos (downloaded from s3)
    local_video_dir = '/media/6TB/Videos/dextro-benchmark2'
    if not os.path.isdir(local_video_dir):
        os.makedirs(local_video_dir)

    # benchmark dataset json file
    json_file = 'dextro_benchmark_2016_02_03.json'

    # download existing video files from s3?
    force_download_from_s3 = False

    # overwrite train/val files?
    overwrite_train_val_file = True

    # save all number of video clips
    save_all_num_segs = True

    # intermediate files
    cwd = os.path.dirname(os.path.realpath(__file__))
    train_file = os.path.join(cwd, 'dextro_benchmark_2016_02_03_train_c3d.txt')
    val_file = os.path.join(cwd, 'dextro_benchmark_2016_02_03_val_c3d.txt')

    random.seed('cerealkiller')
    # 4 means 4:1 = training samples:testing samples
    train_to_val_ratio = 4

    # min num of frames for segment
    c3d_len = 16

    # just in case there's any numeric inaccuracy in frame number calculation,
    # it's good to leave the last few frames unused.
    frame_margin = 2

    # number of frames for stride
    #stride = c3d_len / 2 #-> takes forever for training/testing!
    stride = c3d_len

    # only save content_type mapping and exit
    save_content_type_mapping_only = False

    # minimum number of videos per content_type
    #min_num_videos_per_content_type = 5

    if not os.path.isfile(train_file) or overwrite_train_val_file:
        save_train_val_files = True
    else:
        save_train_val_files = False

    if save_train_val_files:
        train_file_obj = open(train_file, "w")
        val_file_obj = open(val_file, "w")

    # get a list of videos from IW
    video_list = get_all_video_annotations(json_file)

    # limit videos by length (in sec)
    video_length_threshold = (5.0, 9999.0)

    good_video_list, all_content_type_ids, content_id_to_type_mapping = \
            preprocess(
                video_list,
                local_video_dir,
                video_length_threshold=video_length_threshold,
                force_download_from_s3=force_download_from_s3
                )

    # get a number of videos per content type for the splitting training/testing
    # purpose
    num_videos_per_content_type = Counter(all_content_type_ids)

    '''
    print "[debug] all_content_type_ids={}".format(all_content_type_ids)
    print "[debug] num_videos_per_content_type={}".format(
            num_videos_per_content_type
            )

    # remove videos with least frequent content_type's
    good_video_list, all_content_type_ids, content_id_to_type_mapping = \
            remove_uncommon_videos(
            good_video_list,
            num_videos_per_content_type,
            min_num_videos_per_content_type=min_num_videos_per_content_type
            )

    # redo it after pruning videos
    num_videos_per_content_type = Counter(all_content_type_ids)
    print "[debug] all_content_type_ids={}".format(all_content_type_ids)
    print "[debug] num_videos_per_content_type={}".format(
            num_videos_per_content_type
            )
    '''

    # mapping from content_type_id to serial ID starting from 0
    all_uniq_content_type_ids = list(set(all_content_type_ids)) # make unique
    all_content_types = [
            content_id_to_type_mapping[x] for x in all_uniq_content_type_ids
            ]

    if save_content_type_mapping_only:
        print "all_content_types={}".format(all_content_types)
        print "all_uniq_content_type_ids={}".format(all_uniq_content_type_ids)
        with open('content_type_mapping.json', 'w') as json_fp:
            json.dump(all_content_types, json_fp)
        with open('content_type_id_mapping.json', 'w') as json_fp:
            json.dump(all_uniq_content_type_ids, json_fp)
        sys.exit()

    # training/testing splitting
    # a random seed fixed
    random.seed('cerealkiller')
    random.shuffle(good_video_list)
    train_val_separating_index = int(float(len(good_video_list)) *
            train_to_val_ratio / (train_to_val_ratio + 1))
    print("[Info] Number of videos={}, train/val switching index={}"
          "".format(len(good_video_list), train_val_separating_index))

    '''
    # a new logic for training/testing splitting:
    # if number of video samples is too few, use it only for training
    # TODO(chuck): complete a new logic for training/testing splitting
    unordered_good_video_list = good_video_list
    for content_type_id in num_videos_per_content_type.most_common():
        # for less common content_type's, use it for training only
    '''

    all_num_segs = {}

    # sliding window for small segment of frames
    for video_count, video in enumerate(good_video_list):

        # video info
        video_url = video['original_url']
        video_length = video['length']
        print "-" * 79
        print("[Info] Processing video ({}/{}): id={}, original_url={}, "
              "length={}...".format(
                      video_count + 1,
                      len(good_video_list),
                      video['id'],
                      video_url,
                      video_length)
              )

        # get all content_types present in this video
        content_types = video['content_types']

        # get all content_types present in this video
        # get video file / directory of images
        disassembled = urlparse(video_url)
        filename, file_ext = splitext(basename(disassembled.path))
        video_file = os.path.join(local_video_dir, filename + file_ext)

        # get mappings from content_type to temporary "id"
        video_annotations = video['video_annotations']

        # time (second) to frame number conversion
        num_frames = get_num_frames(video_file)

        content_type_map = {}
        for video_annotation in video_annotations:
            content_type_map[
                    video_annotation['id']
                    ] = video_annotation['content_type_id']

        # go over video_annotation_scenes, add clip samples
        for video_annotation_scene in video['video_annotation_scenes']:

            content_type_id = content_type_map[
                    video_annotation_scene['video_annotation_id']
                    ]
            #pylint: disable=W0141,W0110
            content_type = filter(
                    lambda x: x['id'] == content_type_id, content_types
                    )[0]['name']

            new_content_type_id = all_uniq_content_type_ids.index(
                    content_type_id
                    )

            # round start/stop times at first decimal point
            start_time = video_annotation_scene['start']
            stop_time = video_annotation_scene['stop']

            # time to frame conversion
            start_frame = time2frame(start_time, num_frames, video_length)
            stop_frame = time2frame(stop_time, num_frames, video_length) - 1
            scene_length = stop_frame - start_frame + 1

            num_seg = (scene_length - c3d_len - frame_margin) / stride + 1

            print("[Info] -- content_type={}, id={}: t=({}, {}), f=({}, {}), "
                  "#frames={}, num_seg={}, c3d_len={}, stride={}".format(
                          content_type,
                          content_type_id,
                          round(start_time, 1),
                          round(stop_time, 1),
                          start_frame,
                          stop_frame,
                          scene_length,
                          num_seg,
                          c3d_len,
                          stride
                          )
                  )

            for seg_count in range(num_seg):
                seg_start_frame = int(start_frame + seg_count * stride)
                seg_stop_frame = int(
                        start_frame + seg_count * stride + c3d_len - 1
                        )
                seg_stop_frame = min(seg_stop_frame, stop_frame)
                seg_length = seg_stop_frame - seg_start_frame + 1

                # sanity check
                if seg_length < c3d_len:
                    print("[Error] ---- !!!! seg_length < c3d_len: something "
                          "went wrong!")
                    continue

                all_num_segs[content_type] = all_num_segs.get(
                        content_type, 0
                        ) + 1

                text = "{} {} {}\n".format(
                        video_file,
                        seg_start_frame,
                        new_content_type_id
                        )

                # a very simple logic to split up train/val sets
                if save_train_val_files:
                    if video_count < train_val_separating_index:
                        train_file_obj.write(text)
                    else:
                        val_file_obj.write(text)

    print "-" * 79
    print "[Info] all_num_segs={}".format(all_num_segs)

    if save_train_val_files:
        train_file_obj.close()
        val_file_obj.close()

    if save_all_num_segs:

        # save number of video samples per content_type
        all_num_videos_file = os.path.join(
                cwd,
                'all_num_videos_' + time.strftime('%Y_%m_%d') + '.json'
                )
        with open(all_num_videos_file, 'w') as outfile:
            json.dump(num_videos_per_content_type, outfile)

        # save number of segments per content_type
        all_num_segs_file = os.path.join(
                cwd,
                'all_num_segs_' + time.strftime('%Y_%m_%d') + '.json'
                )
        with open(all_num_segs_file, 'w') as outfile:
            json.dump(all_num_segs, outfile)

if __name__ == "__main__":
    main()
